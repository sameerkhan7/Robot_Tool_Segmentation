{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Tool Segmentation using Branch Aggregation Attention Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intoduction\n",
    "\n",
    "Project for Machine Learning: Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm # for notebooks\n",
    "import EndovisDataloader\n",
    "import BBAModule\n",
    "import EncoderModule\n",
    "import TrainingUtils\n",
    "import BAAnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Endovis 2018 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloaders and display test images\n",
    "batch_size = 4\n",
    "reduce_factor = 2 # how much to reduce image size by before training\n",
    "num_workers = 0 # 0 for notebooks\n",
    "train_dataloader, val_dataloader, test_dataloader = EndovisDataloader.getDataloaders(batch_size, reduce_factor, num_workers)\n",
    "\n",
    "# make sure normalization is off first\n",
    "# mean, std = calculate_mean_std(train_dataloader)\n",
    "# print(f\"Mean: {mean}, Std: {std}\")\n",
    "\n",
    "# visualize data \n",
    "images,labels = next(iter(train_dataloader))\n",
    "\n",
    "n = 2\n",
    "cmap = plt.get_cmap('Paired',12)\n",
    "cbar_ticks = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "cbar_labels = [\"Background Tissue\", \"Instrument Shaft\", \"Instrument Clasper\", \"Instrument Wrist\", \"Kidney Parenchyma\", \"Covered Kidney\", \n",
    "               \"Thread\", \"Clamps\", \"Suturing Needle\", \"Suction Instrument\", \"Small Intestine\", \"Ultrasound Probe\"]\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(n, 2, figsize=(20, 20))\n",
    "for i in range(n):  # Flatten the 2D array of axes\n",
    "    axes[i,0].imshow(images[i].permute(1, 2, 0))  \n",
    "    #axes[i,1].imshow(labels[i].permute(1, 2, 0))\n",
    "    label_img = EndovisDataloader.convert_masks_to_gray(labels[i])\n",
    "    im = axes[i,1].imshow(label_img, cmap = cmap, vmin = 0, vmax = 11) # Display the image in grayscale\n",
    "    # colorbar settings\n",
    "    cbar = fig.colorbar(im, ax=axes[i, 1], fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Segmentation Labels\", fontsize=10)\n",
    "    cbar.set_ticks(cbar_ticks)\n",
    "    cbar.set_ticklabels(cbar_labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check encoder and BBA\n",
    "encoder = EncoderModule.MobileNetV2Encoder(pretrained=True)\n",
    "input = images[0:1]\n",
    "label = labels[0:1]\n",
    "print(\"x0:\",input.shape)\n",
    "\n",
    "x1,x2,x3,x4 = encoder(input)\n",
    "\n",
    "print(\"x1:\", x1.shape)\n",
    "print(\"x2:\", x2.shape)\n",
    "print(\"x3:\", x3.shape)\n",
    "print(\"x4:\", x4.shape)\n",
    "\n",
    "channels = [24,32,64,160]\n",
    "BBA = BBAModule.BBAModule(channels)\n",
    "y1,y2,y3,y4 = BBA(x1,x2,x3,x4)\n",
    "\n",
    "print()\n",
    "print(\"y1:\", y1.shape)\n",
    "print(\"y2:\", y2.shape)\n",
    "print(\"y3:\", y3.shape)\n",
    "print(\"y4:\", y4.shape)\n",
    "\n",
    "model = BAAnet.BAANet()\n",
    "y1,y2,y3,y4 = model(input)\n",
    "print()\n",
    "print(\"y1:\", y1.shape)\n",
    "print(\"y2:\", y2.shape)\n",
    "print(\"y3:\", y3.shape)\n",
    "print(\"y4:\", y4.shape)\n",
    "\n",
    "model_BBA = BAAnet.BAANet_BAA_Only()\n",
    "out = model_BBA(input)\n",
    "print()\n",
    "print(\"BAA_Only:\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "epochs = 5\n",
    "lr = 1e-4\n",
    "\n",
    "model = BAAnet.BAANet_BAA_Only().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) # Adam optimizer\n",
    "criterion = TrainingUtils.DICELoss # loss function\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) # learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    TrainingUtils.train(train_dataloader, model, criterion, optimizer, scheduler, i+1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dice, m_iou = TrainingUtils.test(model, val_dataloader, device)\n",
    "print(f\"Mean DICE Score: {m_dice}\")\n",
    "print(f\"Mean IoU Score: {m_iou}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
